{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with the synchronous API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captions\": [\n",
      "    \"Completed tasks list\",\n",
      "    \"Checklist with a completed item\",\n",
      "    \"Verified document\",\n",
      "    \"Task list with a checkmark\",\n",
      "    \"Approved items\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import base64\n",
    "\n",
    "# Load the image\n",
    "with open(\"regularized_data/1.jpg\", \"rb\") as image_file:\n",
    "    image = image_file.read()\n",
    "\n",
    "# Encode the image to base64\n",
    "encoded_image = base64.b64encode(image).decode(\"utf-8\")\n",
    "\n",
    "# Initialization of OpenAI client with your environment API key\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\", \"your-api-key\")\n",
    "\n",
    "# Construct the prompt message for the model\n",
    "PROMPT_MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            \"You are a UI designer generating description for icons to be added as accessibility description for usage in websites and apps , you are to generate 5 captions covering diverse interpretations of the icon based on different UI contexts. The output should be of this following json format : { captions : [ caption1 , caption2 , ... caption5 ] } \",\n",
    "            {\"image\": encoded_image},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Parameters for the API request\n",
    "params = {\n",
    "    \"model\": \"gpt-4o\",  # Make sure you have access to this model\n",
    "    \"messages\": PROMPT_MESSAGES,\n",
    "    \"temperature\":0.1,\n",
    "    \"response_format\":{ \n",
    "        \"type\": \"json_object\"\n",
    "    },\n",
    "    \"max_tokens\": 200,\n",
    "}\n",
    "\n",
    "try:\n",
    "    result = openai.ChatCompletion.create(**params)\n",
    "    print(result.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captions\": [\n",
      "    \"A checklist icon indicating completed tasks or items.\",\n",
      "    \"An icon representing a list with a checkmark, suggesting verification or approval.\",\n",
      "    \"A symbol for organized information, highlighting items that have been confirmed.\",\n",
      "    \"An icon depicting a series of lines with a check, indicating a successful completion of a process.\",\n",
      "    \"A visual cue for task management, showing a list with a tick to denote finished actions.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the API request\n",
    "params = {\n",
    "    \"model\": \"gpt-4o-mini\",  # Make sure you have access to this model\n",
    "    \"messages\": PROMPT_MESSAGES,\n",
    "    \"temperature\":0.1,\n",
    "    \"response_format\":{ \n",
    "        \"type\": \"json_object\"\n",
    "    },\n",
    "    \"max_tokens\": 200,\n",
    "}\n",
    "\n",
    "try:\n",
    "    result = openai.ChatCompletion.create(**params)\n",
    "    print(result.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the batch API in limits\n",
    "\n",
    "Before running this clean up all the stuff above ( restart kernal ) there will be a name space collision with how openai package is imported in the two versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize your OpenAI client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"your-api-key\"))\n",
    "\n",
    "# Specify the image directory and model name\n",
    "image_directory = \"regularized_data\"\n",
    "model_name = \"gpt-4o\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Function to Prepare JSONL File\n",
    "\n",
    "def prepare_jsonl(image_dir, max_images):\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Apply limit to the number of images processed\n",
    "    limit = min(max_images, len(image_files))\n",
    "    selected_images = image_files[:limit]\n",
    "\n",
    "    # Prepare a JSONL file\n",
    "    json_lines = []\n",
    "    for filename in selected_images:\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        with open(file_path, \"rb\") as image_file:\n",
    "            encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "        prompt_messages = [\n",
    "            {\"role\": \"system\", \"content\":\"You are a UI designer generating description for icons to be added as accessibility description for usage in websites and apps , you are to generate 5 captions covering diverse interpretations of the icon based on different UI contexts. The output should be of this following json format : { captions : [ caption1 , caption2 , ... caption5 ] } \" },\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}},]}\n",
    "        ]\n",
    "\n",
    "        json_line = {\n",
    "            \"custom_id\": filename,\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": model_name,\n",
    "                \"messages\": prompt_messages,\n",
    "                \"max_tokens\": 1000,\n",
    "                \"temperature\": 0.1,\n",
    "                \"response_format\":{ \n",
    "                    \"type\": \"json_object\"\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "        json_lines.append(json_line)\n",
    "\n",
    "    # Write to JSONL file\n",
    "    output_jsonl_file = \"batch_input.jsonl\"\n",
    "    with open(output_jsonl_file, \"w\") as f:\n",
    "        for line in json_lines:\n",
    "            f.write(json.dumps(line) + \"\\n\")\n",
    "\n",
    "    print(f\"JSONL file '{output_jsonl_file}' created with {len(json_lines)} entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Upload JSONL File\n",
    "\n",
    "def upload_jsonl(file_path):\n",
    "    try:\n",
    "        batch_input_file = client.files.create(file=open(file_path, \"rb\"), purpose=\"batch\")\n",
    "        print(f\"File uploaded with ID: {batch_input_file.id}\")\n",
    "        return batch_input_file.id\n",
    "    except Exception as e:\n",
    "        print(f\"Uploading failed: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create a Batch\n",
    "\n",
    "def create_batch(file_id):\n",
    "    try:\n",
    "        batch_job = client.batches.create(\n",
    "            input_file_id=file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        print(f\"Batch created with ID: {batch_job.id}\")\n",
    "        return batch_job.id\n",
    "    except Exception as e:\n",
    "        print(f\"Creating batch failed: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Check Batch Status\n",
    "\n",
    "def check_batch_status(batch_id):\n",
    "    try:\n",
    "        batch_job = client.batches.retrieve(batch_id)\n",
    "        print(f\"Batch status: {batch_job.status}\")\n",
    "        return batch_job\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking status: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Download Results\n",
    "\n",
    "def download_results(file_id):\n",
    "    try:\n",
    "        file_response = client.files.content(file_id)\n",
    "        return file_response\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading results: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7a: Specify the Maximum Number of Images\n",
    "\n",
    "# Calculate the total number of images\n",
    "num_images = len([f for f in os.listdir(image_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "# Set max_images to the total number of available images\n",
    "max_images = num_images  # This will set the limit to all image files available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7a: Specify the Maximum Number of Images\n",
    "\n",
    "# Set the maximum number of images to process in this JSONL file\n",
    "max_images = 1   # Adjust this number based on your testing needs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL file 'batch_input.jsonl' created with 1 entries.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7b: Prepare the JSONL File\n",
    "\n",
    "prepare_jsonl(image_directory, max_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded with ID: file-ITN76dJDm3JppCJ4aTU9Uolk\n"
     ]
    }
   ],
   "source": [
    "# Cell 7c: Upload the JSONL File\n",
    "\n",
    "file_id = upload_jsonl(\"batch_input.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch created with ID: batch_dPoFRu7n1hMYHSXS3gj9SqGQ\n"
     ]
    }
   ],
   "source": [
    "# Cell 7d: Create a Batch\n",
    "\n",
    "batch_id = None\n",
    "if file_id:\n",
    "    batch_id = create_batch(file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch status: completed\n",
      "Batch(id='batch_dPoFRu7n1hMYHSXS3gj9SqGQ', completion_window='24h', created_at=1724251803, endpoint='/v1/chat/completions', input_file_id='file-ITN76dJDm3JppCJ4aTU9Uolk', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1724251809, error_file_id=None, errors=None, expired_at=None, expires_at=1724338203, failed_at=None, finalizing_at=1724251808, in_progress_at=1724251804, metadata=None, output_file_id='file-PzrIyvcRLQEdzjqDA8ekQSgs', request_counts=BatchRequestCounts(completed=1, failed=0, total=1))\n"
     ]
    }
   ],
   "source": [
    "# Cell 7e: Manually Check the Batch Status\n",
    "\n",
    "if batch_id:\n",
    "    batch_status = check_batch_status(batch_id)\n",
    "\n",
    "print(batch_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error file ID available.\n"
     ]
    }
   ],
   "source": [
    "# Function to Download Error Details\n",
    "def download_error_file(file_id):\n",
    "    try:\n",
    "        # Get content from the error file\n",
    "        file_content = client.files.content(file_id)\n",
    "        print(\"Error file content:\")\n",
    "        print(file_content.content)\n",
    "        return file_content.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading error file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use this function with the error file ID\n",
    "if batch_status is not None and batch_status.error_file_id:\n",
    "    error_file_content = download_error_file(batch_status.error_file_id)\n",
    "else:\n",
    "    print(\"No error file ID available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions saved to captions.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Cell 7f: Download Results if Completed\n",
    "\n",
    "if batch_status and batch_status.status == \"completed\":\n",
    "    output_file_id = batch_status.output_file_id\n",
    "    results = download_results(output_file_id)\n",
    "    \n",
    "    # Save the result to captions.jsonl\n",
    "    with open(\"captions.jsonl\", \"w\") as f:\n",
    "        f.write(results.text)\n",
    "    print(\"Captions saved to captions.jsonl\")\n",
    "else:\n",
    "    print(f\"Batch status is {batch_status.status}. Check again later.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
